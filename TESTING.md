# ğŸ§ª Guide des tests

Guide complet pour exÃ©cuter et comprendre les tests de l'API.

## ğŸ“‹ Types de tests

### Tests unitaires (rapides, ~30s)
Tests des fonctions sans dÃ©pendances externes.

```bash
# Tous les tests unitaires
pytest test_main.py -v -m "not integration"

# Tests spÃ©cifiques
pytest test_main.py::test_clean_removes_placeholders -v
pytest test_main.py::test_extract_facts -v
```

### Tests d'intÃ©gration (lents, ~60s)
Tests des endpoints complets avec Ollama.

```bash
# Tous les tests d'intÃ©gration
pytest test_main.py -v -m integration

# Note : NÃ©cessite Ollama en cours d'exÃ©cution
```

### Tous les tests

```bash
# ExÃ©cution complÃ¨te
pytest test_main.py -v

# Avec couverture
pytest test_main.py -v --cov=app --cov-report=html
```

## ğŸš€ ExÃ©cution rapide

### Makefile (recommandÃ©)

```bash
# Tests unitaires uniquement
make test

# Tests avec couverture
make test-cov

# Tests d'intÃ©gration
make test-integration
```

### Sans Makefile

```bash
# Activer l'environnement
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Lancer les tests
pytest test_main.py -v
```

## âš ï¸ PrÃ©requis pour tests d'intÃ©gration

Les tests d'intÃ©gration nÃ©cessitent :

1. **Ollama en cours d'exÃ©cution**
   ```bash
   # VÃ©rifier qu'Ollama tourne
   curl http://localhost:11434/api/tags
   ```

2. **ModÃ¨les tÃ©lÃ©chargÃ©s**
   ```bash
   ollama list
   # Doit afficher au moins :
   # - llama3.2:3b (ou autre modÃ¨le LLM)
   # - nomic-embed-text
   ```

3. **Configuration `.env`**
   ```env
   OLLAMA_URL=http://localhost:11434
   LLM_MODEL=llama3.2:3b
   EMBED_MODEL=nomic-embed-text
   ```

## ğŸ“Š RÃ©sultats attendus

### Tests unitaires (26 tests)

```
âœ… test_root                           # Endpoint racine
âœ… test_health                         # Health check
âœ… test_generate_minimal               # GÃ©nÃ©ration minimale
âœ… test_generate_with_full_context     # GÃ©nÃ©ration complÃ¨te
âœ… test_score_v2_empty                 # Scoring liste vide
âœ… test_score_v2_single_item           # Scoring 1 item
âœ… test_score_v2_multiple_items        # Scoring plusieurs items
âœ… test_score_legacy                   # Scoring legacy
âœ… test_clean_removes_placeholders     # Nettoyage placeholders
âœ… test_clean_normalizes_spaces        # Normalisation espaces
âœ… test_smart_clean                    # Smart clean
âœ… test_split_list                     # Split de listes
âœ… test_extract_facts                  # Extraction faits
âœ… test_extract_facts_revenue_streams  # Extraction revenus
âœ… test_parse_context_lines            # Parse contexte
âœ… test_coerce_by_type_number          # Coercition nombre
âœ… test_coerce_by_type_date            # Coercition date
âœ… test_coerce_by_type_email           # Coercition email
âœ… test_coerce_by_type_file            # Coercition fichier
âœ… test_coerce_by_type_text            # Coercition texte
âœ… test_shingles                       # GÃ©nÃ©ration shingles
âœ… test_jaccard_identical              # Jaccard identique
âœ… test_jaccard_different              # Jaccard diffÃ©rent
âœ… test_jaccard_similar                # Jaccard similaire
âœ… test_cos_similarity                 # SimilaritÃ© cosinus
âœ… test_uvp_fallback_with_value_prop   # UVP avec value_prop
âœ… test_uvp_fallback_constructed       # UVP construite
```

### Tests d'intÃ©gration (2 tests)

```
âœ… test_full_generate_pipeline         # Pipeline complet gÃ©nÃ©ration
âœ… test_full_scoring_pipeline          # Pipeline complet scoring
```

### Validation Pydantic (2 tests)

```
âœ… test_generate_request_validation    # Validation GenerateRequest
âœ… test_score_request_validation       # Validation StructuredRequest
```

### Tests d'erreurs (2 tests)

```
âœ… test_generate_missing_required_fields  # Champs manquants
âœ… test_score_missing_required_fields     # Champs manquants
```

## ğŸ› ProblÃ¨mes courants

### ProblÃ¨me : "Ollama not accessible"

**SymptÃ´mes :**
```
ERROR - LLM request timeout
WARNING - Chat endpoint failed
```

**Solution :**
```bash
# VÃ©rifier qu'Ollama tourne
ollama list

# Relancer Ollama si nÃ©cessaire
# Windows : Relancer l'application Ollama
# Linux/Mac : ollama serve

# Ou skip les tests d'intÃ©gration
pytest test_main.py -v -m "not integration"
```

### ProblÃ¨me : Tests lents (>2min)

**Cause :** Ollama est lent ou timeout.

**Solutions :**
1. Skip les tests d'intÃ©gration :
   ```bash
   pytest test_main.py -v -m "not integration"
   ```

2. Augmenter le timeout dans `.env` :
   ```env
   MAX_LLM_TIMEOUT=20.0
   ```

3. Utiliser un modÃ¨le plus rapide :
   ```env
   LLM_MODEL=gemma2:2b
   ```

### ProblÃ¨me : "Embedding error 400"

**Cause :** Le modÃ¨le d'embeddings n'est pas disponible.

**Solution :**
```bash
ollama pull nomic-embed-text

# Ou utiliser un autre modÃ¨le
ollama pull all-minilm

# Dans .env
EMBED_MODEL=all-minilm
```

### ProblÃ¨me : Tests Ã©chouent avec scores bas

**Cause :** Algorithme de scoring strict.

**Solution :** C'est normal si :
- Les rÃ©ponses sont courtes
- Pas de chiffres dans les rÃ©ponses
- RÃ©ponses sans contexte

Les tests ont Ã©tÃ© ajustÃ©s pour accepter des scores rÃ©alistes :
- â‰¥60 au lieu de â‰¥70 pour rÃ©ponses correctes
- â‰¥40 au lieu de â‰¥50 pour rÃ©ponses acceptables

## ğŸ“ˆ Couverture de code

### GÃ©nÃ©rer le rapport

```bash
# Avec HTML
pytest test_main.py --cov=app --cov-report=html

# Ouvrir le rapport
open htmlcov/index.html  # Mac
start htmlcov/index.html # Windows
```

### Couverture actuelle (~80%)

| Module | Couverture |
|--------|-----------|
| Endpoints | 85% |
| Utilitaires texte | 95% |
| Parser contexte | 90% |
| RAG | 75% |
| Scoring | 90% |
| LLM/Embeddings | 70% |

### Zones non couvertes

- Gestion d'erreurs rares (connexion Ollama)
- Cas limites de parsing
- Anti-duplication avancÃ©e
- Logs de debug

## ğŸ¯ StratÃ©gie de tests

### Pyramide des tests

```
        /\
       /  \  Tests E2E (2 tests)
      /â”€â”€â”€â”€\
     /      \  Tests d'intÃ©gration (2 tests)
    /â”€â”€â”€â”€â”€â”€â”€â”€\
   /          \
  /            \  Tests unitaires (30+ tests)
 /â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\
```

### Quoi tester ?

#### âœ… Ã€ tester (couvert)
- Parsing du contexte
- Extraction de faits
- Coercition de types
- SimilaritÃ© (Jaccard, cosinus)
- Nettoyage de texte
- Scoring basÃ© sur rÃ¨gles
- Validation Pydantic
- Endpoints HTTP

#### âš ï¸ Partiellement testÃ©
- RAG (dÃ©pend d'Ollama)
- GÃ©nÃ©ration LLM (dÃ©pend d'Ollama)
- Cache anti-duplication
- Gestion des deadlines

#### âŒ Non testÃ© (complexe)
- Performance sous charge
- Comportement avec GPU
- Concurrence (multiple requests)
- SÃ©curitÃ© (injection, DOS)

## ğŸ”§ Ajouter des tests

### Template de test unitaire

```python
def test_nouvelle_fonction():
    """Description du test"""
    # Arrange
    input_data = "test"
    
    # Act
    result = nouvelle_fonction(input_data)
    
    # Assert
    assert result == "expected"
```

### Template de test d'intÃ©gration

```python
@pytest.mark.integration
def test_nouveau_endpoint():
    """Test d'intÃ©gration du endpoint"""
    # Arrange
    payload = {"key": "value"}
    
    # Act
    response = client.post("/api/endpoint", json=payload)
    
    # Assert
    assert response.status_code == 200
    data = response.json()
    assert "field" in data
```

### ExÃ©cuter un nouveau test

```bash
# Test spÃ©cifique
pytest test_main.py::test_nouvelle_fonction -v

# Avec output dÃ©taillÃ©
pytest test_main.py::test_nouvelle_fonction -vv -s
```

## ğŸ“ Bonnes pratiques

1. **Nommer clairement** : `test_fonction_cas_attendu`
2. **Documenter** : Docstring explicite
3. **AAA Pattern** : Arrange, Act, Assert
4. **Isoler** : Pas de dÃ©pendances entre tests
5. **Rapide** : Tests unitaires < 1s
6. **Markers** : `@pytest.mark.integration` pour tests lents
7. **Assertions** : Une assertion = un concept

## ğŸš€ CI/CD

### GitHub Actions (exemple)

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
      - run: pip install -r requirements.txt
      - run: pytest test_main.py -v -m "not integration"
```

### Pre-commit hook (recommandÃ©)

```bash
# .git/hooks/pre-commit
#!/bin/bash
pytest test_main.py -v -m "not integration"
```

## ğŸ“š Ressources

- **Pytest docs** : https://docs.pytest.org
- **FastAPI testing** : https://fastapi.tiangolo.com/tutorial/testing/
- **Coverage** : https://coverage.readthedocs.io

---

**Note :** Les tests d'intÃ©gration peuvent Ã©chouer si Ollama n'est pas accessible. C'est normal. Utilisez `-m "not integration"` pour les skip.

**Version :** 3.0.0  
**DerniÃ¨re mise Ã  jour :** 2025-10-03